{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url to scrape the songs list from\n",
    "#base_url = \"http://www.hindilyrics.net/lyrics/of-{}.html\"\n",
    "\n",
    "eng_url = \"http://www.hindilyrics.net/lyrics/of-{}.html\"\n",
    "\n",
    "hindi_url = \"https://www.hinditracks.in/{}-lyrics\"\n",
    "\n",
    "songs = [\"Mere Naam Tu\",\"Bhankas\",\"bekhayali\",\"Aira Gaira\",\"Paisa\",\n",
    "         \"Jugraafiya\",\"Issaqbaazi\",\"Husn Parcham\",\n",
    "        \"Dil Royi Jaye\",\"Mukhda Vekh ke\",\"Chale Aana\",\"Humne Rait pe\",\"Hume Tumse Pyaar Kitna\",\n",
    "         \"Manmohini\",\"Phir Mulaaqat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_lyrics = []\n",
    "english_lyrics = []\n",
    "for song in songs:\n",
    "    eng_ly = []\n",
    "    song_ = '%20'.join(x for x in song.lower().split())\n",
    "    #extract English Lyrics\n",
    "    req = eng_url.format(song_)\n",
    "    artist_url = Request(req, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    print(\"Going to url : \", req)\n",
    "    try:\n",
    "        html_page = urlopen(artist_url).read()\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print('Lyrics Not Found')\n",
    "        continue\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_page, 'html.parser')\n",
    "        data = soup.find('pre').text.strip()\n",
    "        for lines in data.splitlines():\n",
    "            eng_ly.append(lines.strip())\n",
    "            #print(lines.strip())\n",
    "    except AttributeError as a:\n",
    "        print('Lyrics Not Found')\n",
    "    #print(eng_ly)\n",
    "        \n",
    "    print('------------------------------------------------')\n",
    "\n",
    "    #extract Hindi Lyrics\n",
    "    hin_ly = []\n",
    "    song_ = '-'.join(x for x in song.lower().split())\n",
    "    req = hindi_url.format(song_)\n",
    "    artist_url = Request(req, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    \n",
    "    print(\"Going to url : \", req)\n",
    "    try:\n",
    "        html_page = urlopen(artist_url).read()\n",
    "    except urllib.error.HTTPError as e:\n",
    "        print('Lyrics Not Found')\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(html_page, 'html.parser')\n",
    "        end = False\n",
    "        divs = soup.find('div',attrs={'id':'hindilyrics'})\n",
    "        hin_ly.append(divs.text.strip())\n",
    "        #print(divs.text.strip())\n",
    "        p = divs.find_next('p')\n",
    "        hin_ly.append(p.text.strip())\n",
    "        #print(p.text.strip())\n",
    "        while not end:\n",
    "            p = p.find_next('p')\n",
    "            #print(p.text.strip())\n",
    "            hin_ly.append(p.text.strip())\n",
    "            if re.match('[A-Za-z0-9]',p.find_next('p').text):\n",
    "                #print(hin_ly)\n",
    "                end = True\n",
    "    except AttributeError as error:\n",
    "        print('Lyrics Not Found')\n",
    "    if len(eng_ly)!=0 and len(hin_ly)!=0:\n",
    "        hindi_lyrics.append(hin_ly)\n",
    "        english_lyrics.append(eng_ly)\n",
    "    else:\n",
    "        continue\n",
    "    print('------------------------------------------------')\n",
    "\n",
    "print(len(hindi_lyrics))\n",
    "print(len(english_lyrics))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./hindi_lyrics.txt','w')\n",
    "for i in range(0,len(hindi_lyrics)):\n",
    "    ly = ''\n",
    "    lines = hindi_lyrics[i]\n",
    "    for l in lines:\n",
    "        if not l.startswith('#'):\n",
    "            l = re.sub(r'[a-zA-Z0-9\\.\\:\\,\\(\\)]','',l)\n",
    "            file.write(l)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./english_lyrics.txt','w')\n",
    "for i in range(0,len(english_lyrics)):\n",
    "    for lines in english_lyrics[i]:\n",
    "        lines = re.sub(r'[\\.\\,\\(\\)]','',lines.lower())\n",
    "        file.writelines(lines+'\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_lyrics = '/home/stuti/Documents/Jan_Intern/GPU/GPU_Train_transliteration/train/hindi_lyrics.txt'\n",
    "english_lyrics = '/home/stuti/Documents/Jan_Intern/GPU/GPU_Train_transliteration/train/english_lyrics.txt'\n",
    "with open(hindi_lyrics) as file:\n",
    "    txt = file.read()\n",
    "    hindi_words = txt.split()\n",
    "with open(english_lyrics) as file:\n",
    "    txt = file.read()\n",
    "    english_words = txt.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('./words_from_songs.csv','w') as outfile:\n",
    "    writer = csv.writer(outfile,escapechar=' ',quoting=csv.QUOTE_NONE)\n",
    "    writer.writerow(['English','Hindi'])\n",
    "    for i in range(len(hindi_words)):\n",
    "        writer.writerow([english_words[i],hindi_words[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
